{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_reset_date(df, col_d='WORK_DATE'):\n",
    "    \"\"\" Sort and reset dataframes based on the date and time\n",
    "\n",
    "    Args:\n",
    "        df: dataframes containing column about the date\n",
    "        col_d: date column of the dataframe, to be manipulated\n",
    "\n",
    "    Returns:\n",
    "        df: sorted dataframe with reset index\n",
    "    \"\"\"\n",
    "    \n",
    "    df.sort_values(by=col_d, inplace=True)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hour_rounder(df, col_t='DEB_TIME'):\n",
    "    \"\"\" Floor down the time to the hour to merge on weather data\n",
    "\n",
    "    Args:\n",
    "        df: dataframe to be modified\n",
    "        col_t: column to be used for floor the time\n",
    "\n",
    "    Returns:\n",
    "        df: updated dataframe with new time floored to the hour\n",
    "    \"\"\"\n",
    "\n",
    "    df['TIME_HOUR'] = pd.to_datetime(df[col_t]).dt.floor('60min')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_time_parade(df):\n",
    "    \"\"\" Calculate time difference between parades and night show (if existing) and the time at each time slot\n",
    "\n",
    "    Args:\n",
    "        df: dataframe to be updated\n",
    "\n",
    "    Returns:\n",
    "        df: updated dataframe with new columns\n",
    "    \"\"\"\n",
    "    \n",
    "    day_duration = (23 - 9) * 60\n",
    "    \n",
    "    df['delta_p1'] = 0\n",
    "    df['delta_p2'] = 0\n",
    "    df['delta_ns'] = 0\n",
    "    df['normalized_delta_p1'] = 0\n",
    "    df['normalized_delta_p2'] = 0\n",
    "    df['normalized_delta_ns'] = 0\n",
    "\n",
    "    deb_list_1 = pd.to_datetime(df[~df['PARADE_1'].isna()]['DEB_TIME']).dt.time\n",
    "    deb_list_2 = pd.to_datetime(df[~df['PARADE_2'].isna()]['DEB_TIME']).dt.time\n",
    "    deb_list_ns = pd.to_datetime(df[~df['NIGHT_SHOW'].isna()]['DEB_TIME']).dt.time\n",
    "\n",
    "    parade_1_list = pd.to_datetime(df[~df['PARADE_1'].isna()]['PARADE_1'], format='%H:%M:%S').dt.time\n",
    "    parade_2_list = pd.to_datetime(df[~df['PARADE_2'].isna()]['PARADE_2'], format='%H:%M:%S').dt.time\n",
    "    parade_night_show = pd.to_datetime(df[~df['NIGHT_SHOW'].isna()]['NIGHT_SHOW'], format='%H:%M:%S').dt.time\n",
    "\n",
    "    # df.loc[~df['PARADE_1'].isna(), 'delta_p1'] = [1-((abs(((c_d.hour - c_tt.hour)*60 + (c_d.minute - c_tt.minute))))/day_duration) for c_d, c_tt in zip(deb_list_1, parade_1_list)]\n",
    "\n",
    "    df.loc[~df['PARADE_1'].isna(), 'delta_p1'] = [((c_d.hour - c_tt.hour)*60 + (c_d.minute - c_tt.minute)) for c_d, c_tt in zip(deb_list_1, parade_1_list)]\n",
    "    df.loc[~df['PARADE_2'].isna(), 'delta_p2'] = [((c_d.hour - c_tt.hour)*60 + (c_d.minute - c_tt.minute)) for c_d, c_tt in zip(deb_list_2, parade_2_list)]\n",
    "    df.loc[~df['NIGHT_SHOW'].isna(), 'delta_ns'] = [((c_d.hour - c_tt.hour)*60 + (c_d.minute - c_tt.minute)) for c_d, c_tt in zip(deb_list_ns, parade_night_show)]\n",
    "\n",
    "    # df.loc[~df['PARADE_1'].isna(), 'normalized_delta_p1'] = [1-((abs(((c_d.hour - c_tt.hour)*60 + (c_d.minute - c_tt.minute))))/day_duration) for c_d, c_tt in zip(deb_list_1, parade_1_list)]\n",
    "    # df.loc[~df['PARADE_2'].isna(), 'normalized_delta_p2'] = [1-((abs(((c_d.hour - c_tt.hour)*60 + (c_d.minute - c_tt.minute))))/day_duration) for c_d, c_tt in zip(deb_list_2, parade_2_list)]\n",
    "    # df.loc[~df['NIGHT_SHOW'].isna(), 'normalized_delta_ns'] = [1-((abs(((c_d.hour - c_tt.hour)*60 + (c_d.minute - c_tt.minute))))/day_duration) for c_d, c_tt in zip(deb_list_ns, parade_night_show)]\n",
    "\n",
    "    df.loc[~df['PARADE_1'].isna(), 'normalized_delta_p1'] = [1-(abs(c_d)/day_duration) for c_d in df[~df['PARADE_1'].isna()]['delta_p1']]\n",
    "    df.loc[~df['PARADE_2'].isna(), 'normalized_delta_p2'] = [1-(abs(c_d)/day_duration) for c_d in df[~df['PARADE_2'].isna()]['delta_p2']]\n",
    "    df.loc[~df['NIGHT_SHOW'].isna(), 'normalized_delta_ns'] = [1-(abs(c_d)/day_duration) for c_d in df[~df['NIGHT_SHOW'].isna()]['delta_ns']]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\" Load all the attendance, weather and waiting data\n",
    "\n",
    "    Returns:\n",
    "        attendance, entity_schedule, link_attraction, parade_night_show, waiting_times, weather_data: All dataframes returned by the function\n",
    "    \"\"\"\n",
    "    \n",
    "    print('Data Loading...')\n",
    "    attendance = pd.read_csv(r'data/attendance.csv')\n",
    "    entity_schedule = pd.read_csv(r'data/entity_schedule.csv')\n",
    "    # glossary = pd.read_excel(r'data/glossary.xlsx')\n",
    "    link_attraction = pd.read_csv(r'data/link_attraction_park.csv', sep=';')\n",
    "    parade_night_show = pd.read_excel(r'data/parade_night_show.xlsx')\n",
    "    waiting_times = pd.read_csv(r'data/waiting_times.csv')\n",
    "    weather_data = pd.read_csv(r'data/weather_data.csv')\n",
    "\n",
    "    parade_night_show.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "    print('Data Loaded!')\n",
    "\n",
    "    return attendance, entity_schedule, link_attraction, parade_night_show, waiting_times, weather_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data(attendance, entity_schedule, link_attraction, parade_night_show, waiting_times, weather_data):\n",
    "    \"\"\" Basic preprocessing and data clearning to allow merging\n",
    "\n",
    "    Args:\n",
    "        attendance: Attendance dataframe containing attendance per day\n",
    "        entity_schedule: Dataframe containing maintenance data\n",
    "        link_attraction: Dataframe linking attractions to respective parks\n",
    "        parade_night_show: Dataframe containing planned night shows and parades for the park\n",
    "        waiting_times: Dataframe containing waiting times\n",
    "        weather_data: Weather dataframe\n",
    "\n",
    "    Returns:\n",
    "        waiting_times, attendance, entity_schedule_pa, parade_night_show, weather_data: Preprocessed and cleaned dataframes ready for merging\n",
    "    \"\"\"\n",
    "    print('Data Preprocessing...')\n",
    "    attendance = attendance[attendance['FACILITY_NAME'] == 'PortAventura World']\n",
    "    lst_attr = link_attraction[link_attraction['PARK'] == 'PortAventura World']['ATTRACTION']\n",
    "    entity_schedule_pa = entity_schedule[entity_schedule['ENTITY_DESCRIPTION_SHORT'].isin(lst_attr)]\n",
    "    waiting_times = waiting_times[waiting_times['ENTITY_DESCRIPTION_SHORT'].isin(lst_attr)]\n",
    "    attendance = attendance[attendance['attendance']>=0] # replace with median or mean\n",
    "    \n",
    "    # Sort Dates and reset index\n",
    "    attendance = sort_reset_date(attendance, 'USAGE_DATE')\n",
    "    entity_schedule_pa = sort_reset_date(entity_schedule_pa, 'DEB_TIME')\n",
    "    parade_night_show = sort_reset_date(parade_night_show, 'WORK_DATE')\n",
    "    waiting_times = sort_reset_date(waiting_times, 'DEB_TIME')\n",
    "    weather_data = sort_reset_date(weather_data, 'dt_iso')\n",
    "\n",
    "    # Delete columns and some preprocessing\n",
    "    weather_data['dt_iso'] = pd.to_datetime(weather_data['dt_iso'].str.replace(\" +0000 UTC\", \"\", regex=False), errors='coerce', format='%Y-%m-%d %H:%M:%S')\n",
    "    cols_del = ['city_name', 'lat', 'lon', 'weather_id', 'visibility', 'sea_level', 'grnd_level', 'wind_gust', 'snow_3h']\n",
    "    weather_data.drop(columns=cols_del, inplace=True)\n",
    "    weather_data.fillna(0, inplace=True)\n",
    "    attendance.rename(columns={'USAGE_DATE': 'WORK_DATE'}, inplace=True)\n",
    "    # weather_data.rename(columns={'dt_iso': 'TIME_HOUR'}, inplace=True)\n",
    "\n",
    "    attendance['WORK_DATE'] = pd.to_datetime(attendance['WORK_DATE'])\n",
    "    waiting_times['WORK_DATE'] = pd.to_datetime(waiting_times['WORK_DATE'])\n",
    "    parade_night_show['WORK_DATE'] = pd.to_datetime(parade_night_show['WORK_DATE'])\n",
    "\n",
    "    weather_data = hour_rounder(weather_data, col_t='dt_iso')\n",
    "    waiting_times = hour_rounder(waiting_times, col_t='DEB_TIME')\n",
    "    entity_schedule_pa = hour_rounder(entity_schedule_pa, col_t='DEB_TIME')\n",
    "    print('Data Preprocessed!')\n",
    "    \n",
    "    return waiting_times, attendance, entity_schedule_pa, parade_night_show, weather_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(waiting_times, attendance, entity_schedule_pa, parade_night_show, weather_data):\n",
    "    \"\"\"Merging dataframes into one final dataframe for prediction\n",
    "\n",
    "    Args:\n",
    "        waiting_times: Dataframe containing waiting times\n",
    "        attendance: Attendance dataframe containing attendance per day\n",
    "        entity_schedule_pa: Dataframe containing maintenance data\n",
    "        parade_night_show: Dataframe containing planned night shows and parades for the park\n",
    "        weather_data: Weather dataframe\n",
    "\n",
    "    Returns:\n",
    "        df_m: Merged dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    print('Merging Data...')\n",
    "    # Merge the dataframes\n",
    "    df_m = waiting_times.merge(attendance[['WORK_DATE', 'attendance']], how='left', on='WORK_DATE')\n",
    "    df_m = df_m.merge(entity_schedule_pa[['TIME_HOUR', 'ENTITY_DESCRIPTION_SHORT', 'REF_CLOSING_DESCRIPTION', 'ENTITY_TYPE', 'UPDATE_TIME']], how='left', on=['TIME_HOUR', 'ENTITY_DESCRIPTION_SHORT'])\n",
    "    df_m = df_m.merge(parade_night_show, how='left', on='WORK_DATE')\n",
    "    df_m = df_m.merge(weather_data, how='left', on='TIME_HOUR')\n",
    "    print('Data Merged!')\n",
    "    \n",
    "    return df_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_addition(df):\n",
    "    \n",
    "    df['timet'] = [((c_d.hour - 9)*4 + c_d.minute/15) for c_d in pd.to_datetime(df['DEB_TIME']).dt.time]\n",
    "    \n",
    "    df['delta_open_scaled'] = df['attendance']\n",
    "    df[df['timet']<12]['delta_open_scaled'] = (df[df['timet']<12]['attendance']*df[df['timet']<12]['timet']/12)\n",
    "    df[df['timet']>27]['delta_open_scaled'] = (55-(df[df['timet']>27]['attendance']*df[df['timet']>27]['timet']/28))\n",
    "    \n",
    "    df['delta_open_normalized'] = 1\n",
    "    df[df['timet']<12]['delta_open_normalized'] = (df[df['timet']<12]['timet']/12)\n",
    "    df[df['timet']>27]['delta_open_normalized'] = ((55-df[df['timet']>27]['timet'])/28)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df():\n",
    "    \"\"\" Function combining all loading, preprocessing and merging functions\n",
    "\n",
    "    Returns:\n",
    "        df_m: Merged and finalized dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    attendance, entity_schedule, link_attraction, parade_night_show, waiting_times, weather_data = load_data()\n",
    "    waiting_times, attendance, entity_schedule_pa, parade_night_show, weather_data = preprocessing_data(attendance, entity_schedule, link_attraction, parade_night_show, waiting_times, weather_data)\n",
    "    df_m = merge_data(waiting_times, attendance, entity_schedule_pa, parade_night_show, weather_data)\n",
    "    df_m = delta_time_parade(df_m)\n",
    "    df_m = feature_addition(df_m)\n",
    "    \n",
    "    # cols_del = ['dt', 'dt_iso', 'timezone', 'NIGHT_SHOW', 'PARADE_1', 'PARADE_2', 'TIME_HOUR', 'DEB_TIME_HOUR']\n",
    "    # df_m.drop(columns=cols_del, inplace=True)\n",
    "    \n",
    "    print('Dataframe Finalized!')\n",
    "\n",
    "    return df_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loading...\n",
      "Data Loaded!\n",
      "Data Preprocessing...\n",
      "Data Preprocessed!\n",
      "Merging Data...\n",
      "Data Merged!\n",
      "Dataframe Finalized!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEB_TIME</th>\n",
       "      <th>PARADE_1</th>\n",
       "      <th>delta_p1</th>\n",
       "      <th>PARADE_2</th>\n",
       "      <th>delta_p2</th>\n",
       "      <th>NIGHT_SHOW</th>\n",
       "      <th>delta_ns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 09:00:00.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 09:00:00.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 09:00:00.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 09:00:00.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 09:00:00.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2369816</th>\n",
       "      <td>2022-08-18 22:45:00.000</td>\n",
       "      <td>17:30:00</td>\n",
       "      <td>315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2369817</th>\n",
       "      <td>2022-08-18 22:45:00.000</td>\n",
       "      <td>17:30:00</td>\n",
       "      <td>315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2369818</th>\n",
       "      <td>2022-08-18 22:45:00.000</td>\n",
       "      <td>17:30:00</td>\n",
       "      <td>315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2369819</th>\n",
       "      <td>2022-08-18 22:45:00.000</td>\n",
       "      <td>17:30:00</td>\n",
       "      <td>315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2369820</th>\n",
       "      <td>2022-08-18 22:45:00.000</td>\n",
       "      <td>17:30:00</td>\n",
       "      <td>315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2369821 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        DEB_TIME  PARADE_1  delta_p1 PARADE_2  delta_p2  \\\n",
       "0        2018-01-01 09:00:00.000       NaN         0      NaN         0   \n",
       "1        2018-01-01 09:00:00.000       NaN         0      NaN         0   \n",
       "2        2018-01-01 09:00:00.000       NaN         0      NaN         0   \n",
       "3        2018-01-01 09:00:00.000       NaN         0      NaN         0   \n",
       "4        2018-01-01 09:00:00.000       NaN         0      NaN         0   \n",
       "...                          ...       ...       ...      ...       ...   \n",
       "2369816  2022-08-18 22:45:00.000  17:30:00       315      NaN         0   \n",
       "2369817  2022-08-18 22:45:00.000  17:30:00       315      NaN         0   \n",
       "2369818  2022-08-18 22:45:00.000  17:30:00       315      NaN         0   \n",
       "2369819  2022-08-18 22:45:00.000  17:30:00       315      NaN         0   \n",
       "2369820  2022-08-18 22:45:00.000  17:30:00       315      NaN         0   \n",
       "\n",
       "        NIGHT_SHOW  delta_ns  \n",
       "0              NaN         0  \n",
       "1              NaN         0  \n",
       "2              NaN         0  \n",
       "3              NaN         0  \n",
       "4              NaN         0  \n",
       "...            ...       ...  \n",
       "2369816   23:00:00       -15  \n",
       "2369817   23:00:00       -15  \n",
       "2369818   23:00:00       -15  \n",
       "2369819   23:00:00       -15  \n",
       "2369820   23:00:00       -15  \n",
       "\n",
       "[2369821 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m = create_df()\n",
    "df_m[['DEB_TIME', 'PARADE_1', 'delta_p1', 'PARADE_2', 'delta_p2', 'NIGHT_SHOW', 'delta_ns']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check plot of attendance or waiting depending on weather per day groupby, or sthg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.signal import argrelextrema\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# n=5\n",
    "# df_peaks = df_m[['timet', 'WAIT_TIME_MAX']].groupby(by='timet').mean()\n",
    "# df_peaks.plot()\n",
    "# df_peaks['min'] = df_peaks.iloc[argrelextrema(df_peaks.WAIT_TIME_MAX.values, np.less_equal,\n",
    "#                     order=n)[0]]['WAIT_TIME_MAX']\n",
    "# df_peaks['max'] = df_peaks.iloc[argrelextrema(df_peaks.WAIT_TIME_MAX.values, np.greater_equal,\n",
    "#                     order=n)[0]]['WAIT_TIME_MAX']\n",
    "# # df_m[['timet', 'WAIT_TIME_MAX']].groupby(by='timet').mean()\n",
    "\n",
    "# plt.scatter(df_peaks.index, df_peaks['min'], c='r')\n",
    "# plt.scatter(df_peaks.index, df_peaks['max'], c='g')\n",
    "# plt.plot(df_peaks.index, df_peaks['WAIT_TIME_MAX'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peaks[~df_peaks['max'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peaks[~df_peaks['min'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_del = ['dt', 'dt_iso', 'timezone', 'NIGHT_SHOW', 'PARADE_1', 'PARADE_2', 'TIME_HOUR', 'DEB_TIME_HOUR']\n",
    "df_m.drop(columns=cols_del, inplace=True)\n",
    "df_m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m.isna().sum()[df_m.isna().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pensez a l'heure d'ouverture et de fermeture (avec un gap pour l'heure du repas)\n",
    "# Garder le meme calcul pour le night show knowing that park is closed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m[df_m.attendance.isna()]['WORK_DATE'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attendance = pd.read_csv(r'data/attendance.csv')\n",
    "# entity_schedule = pd.read_csv(r'data/entity_schedule.csv')\n",
    "# # glossary = pd.read_excel(r'data/glossary.xlsx')\n",
    "# link_attraction = pd.read_csv(r'data/link_attraction_park.csv', sep=';')\n",
    "# parade_night_show = pd.read_excel(r'data/parade_night_show.xlsx')\n",
    "# waiting_times = pd.read_csv(r'data/waiting_times.csv')\n",
    "# weather_data = pd.read_csv(r'data/weather_data.csv')\n",
    "\n",
    "# parade_night_show.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attendance = attendance[attendance['FACILITY_NAME'] == 'PortAventura World']\n",
    "# lst_attr = link_attraction[link_attraction['PARK'] == 'PortAventura World']['ATTRACTION']\n",
    "# entity_schedule_pa = entity_schedule[entity_schedule['ENTITY_DESCRIPTION_SHORT'].isin(lst_attr)]\n",
    "# waiting_times = waiting_times[waiting_times['ENTITY_DESCRIPTION_SHORT'].isin(lst_attr)]\n",
    "# attendance = attendance[attendance['attendance']>=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sort Dates and reset index\n",
    "# attendance = sort_reset_date(attendance, 'USAGE_DATE')\n",
    "# entity_schedule_pa = sort_reset_date(entity_schedule_pa, 'DEB_TIME')\n",
    "# parade_night_show = sort_reset_date(parade_night_show, 'WORK_DATE')\n",
    "# waiting_times = sort_reset_date(waiting_times, 'DEB_TIME')\n",
    "# weather_data = sort_reset_date(weather_data, 'dt_iso')\n",
    "\n",
    "# # Delete columns and some preprocessing\n",
    "# weather_data['dt_iso'] = pd.to_datetime(weather_data['dt_iso'].str.replace(\" +0000 UTC\", \"\", regex=False), errors='coerce', format='%Y-%m-%d %H:%M:%S')\n",
    "# cols_del = ['city_name', 'lat', 'lon', 'weather_id', 'visibility', 'sea_level', 'grnd_level', 'wind_gust', 'snow_3h']\n",
    "# weather_data.drop(columns=cols_del, inplace=True)\n",
    "# weather_data.fillna(0, inplace=True)\n",
    "# attendance.rename(columns={'USAGE_DATE': 'WORK_DATE'}, inplace=True)\n",
    "# # weather_data.rename(columns={'dt_iso': 'TIME_HOUR'}, inplace=True)\n",
    "\n",
    "# attendance['WORK_DATE'] = pd.to_datetime(attendance['WORK_DATE'])\n",
    "# waiting_times['WORK_DATE'] = pd.to_datetime(waiting_times['WORK_DATE'])\n",
    "# parade_night_show['WORK_DATE'] = pd.to_datetime(parade_night_show['WORK_DATE'])\n",
    "\n",
    "# weather_data = hour_rounder(weather_data, col_t='dt_iso')\n",
    "# waiting_times = hour_rounder(waiting_times, col_t='DEB_TIME')\n",
    "# entity_schedule_pa = hour_rounder(entity_schedule_pa, col_t='DEB_TIME')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Merge the dataframes\n",
    "# df_m = waiting_times.merge(attendance[['WORK_DATE', 'attendance']], how='left', on='WORK_DATE')\n",
    "# df_m = df_m.merge(entity_schedule_pa[['TIME_HOUR', 'ENTITY_DESCRIPTION_SHORT', 'REF_CLOSING_DESCRIPTION', 'ENTITY_TYPE', 'UPDATE_TIME']], how='left', on=['TIME_HOUR', 'ENTITY_DESCRIPTION_SHORT'])\n",
    "# df_m = df_m.merge(parade_night_show, how='left', on='WORK_DATE')\n",
    "# df_m = df_m.merge(weather_data, how='left', on='TIME_HOUR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# day_duration = (23 - 9) * 60\n",
    "\n",
    "# df_m['delta_p1'] = 0\n",
    "# df_m['delta_p2'] = 0\n",
    "# df_m['delta_ns'] = 0\n",
    "\n",
    "# deb_list_1 = pd.to_datetime(df_m[~df_m['PARADE_1'].isna()]['DEB_TIME']).dt.time\n",
    "# deb_list_2 = pd.to_datetime(df_m[~df_m['PARADE_2'].isna()]['DEB_TIME']).dt.time\n",
    "# deb_list_ns = pd.to_datetime(df_m[~df_m['NIGHT_SHOW'].isna()]['DEB_TIME']).dt.time\n",
    "\n",
    "# parade_1_list = pd.to_datetime(df_m[~df_m['PARADE_1'].isna()]['PARADE_1'], format='%H:%M:%S').dt.time\n",
    "# parade_2_list = pd.to_datetime(df_m[~df_m['PARADE_2'].isna()]['PARADE_2'], format='%H:%M:%S').dt.time\n",
    "# parade_night_show = pd.to_datetime(df_m[~df_m['NIGHT_SHOW'].isna()]['NIGHT_SHOW'], format='%H:%M:%S').dt.time\n",
    "\n",
    "# df_m.loc[~df_m['PARADE_1'].isna(), 'delta_p1'] = [1-((abs(((c_d.hour - c_tt.hour)*60 + (7.5 + c_d.minute - c_tt.minute))))/day_duration) for c_d, c_tt in zip(deb_list_1, parade_1_list)]\n",
    "\n",
    "# df_m.loc[~df_m['PARADE_1'].isna(), 'delta_p1'] = [1-((abs(((c_d.hour - c_tt.hour)*60 + (7.5 + c_d.minute - c_tt.minute))))/day_duration) for c_d, c_tt in zip(deb_list_1, parade_1_list)]\n",
    "# df_m.loc[~df_m['PARADE_2'].isna(), 'delta_p2'] = [1-((abs(((c_d.hour - c_tt.hour)*60 + (7.5 + c_d.minute - c_tt.minute))))/day_duration) for c_d, c_tt in zip(deb_list_2, parade_2_list)]\n",
    "# df_m.loc[~df_m['NIGHT_SHOW'].isna(), 'delta_ns'] = [1-((abs(((c_d.hour - c_tt.hour)*60 + (7.5 + c_d.minute - c_tt.minute))))/day_duration) for c_d, c_tt in zip(deb_list_ns, parade_night_show)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_m = delta_time_parade(df_m)\n",
    "\n",
    "# df_m[['DEB_TIME', 'PARADE_1', 'delta_p1', 'PARADE_2', 'delta_p2', 'NIGHT_SHOW', 'delta_ns']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "096d4302486a5f76f9b50d582eb8507d0f454f0513db05604f74a7cecd9e1d14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
